{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963c4d83",
   "metadata": {},
   "source": [
    "# Interactive Parts of Speech (POS) Tagging Workshop\n",
    "\n",
    "Welcome to this interactive workshop on Parts of Speech (POS) Tagging in Natural Language Processing! This notebook will guide you through the fundamentals and advanced concepts of POS tagging, with hands-on examples and interactive visualizations.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Basic Implementation](#basic)\n",
    "3. [Interactive Concept Explanation](#interactive)\n",
    "4. [Advanced Implementation](#advanced)\n",
    "5. [Data Flow Visualization](#visualization)\n",
    "6. [Challenges & Edge Cases](#challenges)\n",
    "7. [Conclusion & Further Reading](#conclusion)\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d830af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, interactive, fixed, widgets\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f083de",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "## 1. Introduction\n",
    "\n",
    "Parts of Speech (POS) tagging is a fundamental task in Natural Language Processing that involves assigning grammatical categories (like noun, verb, adjective, etc.) to each word in a sentence. This process is crucial for understanding the syntactic structure of text and is used as a preprocessing step in many NLP applications.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Parts of Speech Categories**\n",
    "   - Nouns (NN): names of people, places, things, or ideas\n",
    "   - Verbs (VB): actions or states of being\n",
    "   - Adjectives (JJ): words that describe nouns\n",
    "   - Adverbs (RB): words that modify verbs, adjectives, or other adverbs\n",
    "   - Pronouns (PRP): words that replace nouns\n",
    "   - Prepositions (IN): words that show relationships between words\n",
    "   - Conjunctions (CC): words that connect words or phrases\n",
    "   - Determiners (DT): words that introduce nouns\n",
    "\n",
    "2. **Tagging Techniques**\n",
    "   - Rule-based tagging\n",
    "   - Statistical tagging (Hidden Markov Models)\n",
    "   - Deep Learning-based tagging\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "1. **Syntactic Analysis**\n",
    "   - Understanding sentence structure\n",
    "   - Identifying grammatical relationships\n",
    "   - Building parse trees\n",
    "\n",
    "2. **Named Entity Recognition**\n",
    "   - Identifying proper nouns\n",
    "   - Extracting named entities\n",
    "   - Entity classification\n",
    "\n",
    "3. **Sentiment Analysis**\n",
    "   - Identifying opinion-bearing words\n",
    "   - Understanding context\n",
    "   - Analyzing sentiment patterns\n",
    "\n",
    "4. **Machine Translation**\n",
    "   - Understanding word roles\n",
    "   - Maintaining grammatical structure\n",
    "   - Handling word order differences\n",
    "\n",
    "### Example Use Cases\n",
    "\n",
    "1. **Chatbots**\n",
    "   - Understanding user intent\n",
    "   - Generating grammatically correct responses\n",
    "   - Handling complex queries\n",
    "\n",
    "2. **Grammar Checking**\n",
    "   - Identifying grammatical errors\n",
    "   - Suggesting corrections\n",
    "   - Improving writing quality\n",
    "\n",
    "3. **Financial Text Analysis**\n",
    "   - Extracting key financial terms\n",
    "   - Understanding market sentiment\n",
    "   - Analyzing financial reports\n",
    "\n",
    "Let's start by implementing a basic POS tagger to understand the fundamentals!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b2106",
   "metadata": {},
   "source": [
    "<a id='basic'></a>\n",
    "## 2. Basic Implementation\n",
    "\n",
    "Let's implement a basic POS tagger from scratch to understand the fundamental concepts. We'll create a simple rule-based tagger that uses pattern matching and basic linguistic rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2909468b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801415f1818f4cb3aaad411e048f36f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The quick brown fox jumps over the lazy dog.', description='Text:', layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare_taggers(text)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_pos_tagger(word):\n",
    "    \"\"\"A simple rule-based POS tagger\"\"\"\n",
    "    # Basic rules for POS tagging\n",
    "    if word.endswith(('ing', 'ed', 's')):\n",
    "        return 'VB'\n",
    "    elif word.endswith(('ly')):\n",
    "        return 'RB'\n",
    "    elif word.endswith(('able', 'ible', 'ful', 'less', 'ous')):\n",
    "        return 'JJ'\n",
    "    elif word.endswith(('tion', 'sion', 'ment', 'ness')):\n",
    "        return 'NN'\n",
    "    elif word.lower() in ['the', 'a', 'an']:\n",
    "        return 'DT'\n",
    "    elif word.lower() in ['and', 'or', 'but']:\n",
    "        return 'CC'\n",
    "    elif word.lower() in ['in', 'on', 'at', 'to', 'for', 'of', 'with']:\n",
    "        return 'IN'\n",
    "    else:\n",
    "        return 'NN'  # Default to noun\n",
    "\n",
    "def compare_taggers(text):\n",
    "    \"\"\"Compare our basic tagger with NLTK and spaCy\"\"\"\n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Get tags from different taggers\n",
    "    basic_tags = [basic_pos_tagger(word) for word in words]\n",
    "    nltk_tags = nltk.pos_tag(words)  # This returns a list of (word, tag) tuples\n",
    "    \n",
    "    # Process with spaCy\n",
    "    doc = nlp(text)\n",
    "    spacy_tags = [token.pos_ for token in doc]\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Word': words,\n",
    "        'Basic Tagger': basic_tags,\n",
    "        'NLTK Tagger': [tag for word, tag in nltk_tags],  # Fixed unpacking\n",
    "        'spaCy Tagger': spacy_tags\n",
    "    })\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nInput text: '{text}'\\n\")\n",
    "    print(\"POS Tagging Results:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Calculate accuracy (compared to NLTK as reference)\n",
    "    basic_accuracy = sum(1 for i in range(len(words)) \n",
    "                        if basic_tags[i] == nltk_tags[i][1]) / len(words)\n",
    "    spacy_accuracy = sum(1 for i in range(len(words)) \n",
    "                        if spacy_tags[i] == nltk_tags[i][1]) / len(words)\n",
    "    \n",
    "    print(f\"\\nAccuracy (compared to NLTK):\")\n",
    "    print(f\"Basic Tagger: {basic_accuracy:.2%}\")\n",
    "    print(f\"spaCy Tagger: {spacy_accuracy:.2%}\")\n",
    "\n",
    "# Create interactive widget\n",
    "text_input = widgets.Textarea(\n",
    "    value='The quick brown fox jumps over the lazy dog.',\n",
    "    placeholder='Enter text to analyze...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(compare_taggers, text=text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83d67c",
   "metadata": {},
   "source": [
    "### Understanding the Basic Implementation\n",
    "\n",
    "Our basic POS tagger uses pattern matching to identify parts of speech based on word patterns and endings. Here's how it works:\n",
    "\n",
    "1. **Pattern Matching**\n",
    "   - Uses regular expressions to match word patterns\n",
    "   - Assigns POS tags based on matching patterns\n",
    "   - Handles common word endings and forms\n",
    "\n",
    "2. **Limitations**\n",
    "   - Cannot handle irregular forms\n",
    "   - May miss context-dependent meanings\n",
    "   - Limited to basic patterns\n",
    "\n",
    "3. **Comparison with NLTK**\n",
    "   - Shows accuracy compared to professional tagger\n",
    "   - Highlights areas for improvement\n",
    "   - Demonstrates the complexity of POS tagging\n",
    "\n",
    "Try entering different sentences to see how our basic tagger performs compared to NLTK's more sophisticated implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e0ed2",
   "metadata": {},
   "source": [
    "<a id='interactive'></a>\n",
    "## 3. Interactive Concept Explanation\n",
    "\n",
    "Let's explore how POS tagging works on different sentences through interactive visualizations. We'll create tools to help you understand the tagging process and see how different words are categorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aae7d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd440373f084cddaa24438dc31a5825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The quick brown fox jumps over the lazy dog.', description='Sentence:', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize_pos_tags(sentence)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_pos_tags(sentence):\n",
    "    \"\"\"Create an interactive visualization of POS tags\"\"\"\n",
    "    # Get POS tags from NLTK\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Create a color-coded visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Define colors for different POS categories\n",
    "    pos_colors = {\n",
    "        'NN': '#FF9999',  # Nouns\n",
    "        'VB': '#66B2FF',  # Verbs\n",
    "        'JJ': '#99FF99',  # Adjectives\n",
    "        'RB': '#FFCC99',  # Adverbs\n",
    "        'PRP': '#FF99CC', # Pronouns\n",
    "        'IN': '#99CCFF',  # Prepositions\n",
    "        'CC': '#FFB366',  # Conjunctions\n",
    "        'DT': '#FF99FF',  # Determiners\n",
    "        'OTHER': '#CCCCCC' # Other categories\n",
    "    }\n",
    "    \n",
    "    # Create bars for each word\n",
    "    words = [word for word, _ in pos_tags]\n",
    "    tags = [tag for _, tag in pos_tags]\n",
    "    \n",
    "    # Get colors for each tag\n",
    "    colors = [pos_colors.get(tag[:2], pos_colors['OTHER']) for tag in tags]\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = plt.bar(range(len(words)), [1] * len(words), color=colors)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xticks(range(len(words)), words, rotation=45, ha='right')\n",
    "    plt.yticks([])\n",
    "    plt.title('POS Tag Visualization')\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=color, label=pos)\n",
    "                      for pos, color in pos_colors.items()]\n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display detailed tag information\n",
    "    print(\"\\nDetailed POS Tag Information:\")\n",
    "    for word, tag in pos_tags:\n",
    "        print(f\"{word}: {tag}\")\n",
    "\n",
    "# Create interactive widget\n",
    "sentence_input = widgets.Textarea(\n",
    "    value='The quick brown fox jumps over the lazy dog.',\n",
    "    placeholder='Enter a sentence for POS visualization...',\n",
    "    description='Sentence:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(visualize_pos_tags, sentence=sentence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de202d",
   "metadata": {},
   "source": [
    "### Understanding the Visualization\n",
    "\n",
    "The interactive visualization above shows how different words in a sentence are tagged with their parts of speech. Here's what the colors represent:\n",
    "\n",
    "1. **Nouns (Red)**\n",
    "   - Names of people, places, things, or ideas\n",
    "   - Can be singular or plural\n",
    "   - Can be proper or common\n",
    "\n",
    "2. **Verbs (Blue)**\n",
    "   - Actions or states of being\n",
    "   - Can be in different tenses\n",
    "   - Can be main verbs or auxiliaries\n",
    "\n",
    "3. **Adjectives (Green)**\n",
    "   - Words that describe nouns\n",
    "   - Can be comparative or superlative\n",
    "   - Can be attributive or predicative\n",
    "\n",
    "4. **Adverbs (Orange)**\n",
    "   - Words that modify verbs, adjectives, or other adverbs\n",
    "   - Often end in '-ly'\n",
    "   - Can indicate manner, time, place, or degree\n",
    "\n",
    "5. **Pronouns (Pink)**\n",
    "   - Words that replace nouns\n",
    "   - Can be personal, possessive, or demonstrative\n",
    "   - Help avoid repetition\n",
    "\n",
    "6. **Prepositions (Light Blue)**\n",
    "   - Words that show relationships between words\n",
    "   - Often indicate location, direction, or time\n",
    "   - Form prepositional phrases\n",
    "\n",
    "7. **Conjunctions (Light Orange)**\n",
    "   - Words that connect words or phrases\n",
    "   - Can be coordinating or subordinating\n",
    "   - Help create complex sentences\n",
    "\n",
    "8. **Determiners (Purple)**\n",
    "   - Words that introduce nouns\n",
    "   - Include articles and quantifiers\n",
    "   - Help specify which noun is being referred to\n",
    "\n",
    "Try entering different sentences to see how the POS tags change and how different words are categorized!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b385ae6",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "## 4. Advanced Implementation with Libraries\n",
    "\n",
    "Now that we understand the basics, let's explore advanced POS tagging using popular NLP libraries. We'll compare different tagging methods and analyze their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b41f2757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25eb735f0e8b43de8c9788b036b34332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The quick brown fox jumps over the lazy dog.', description='Text:', layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare_pos_taggers(text)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_pos_taggers(text):\n",
    "    \"\"\"Compare different POS tagging methods\"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Get tags from different taggers\n",
    "    nltk_tags = nltk.pos_tag(tokens)\n",
    "    spacy_doc = nlp(text)\n",
    "    spacy_tags = [(token.text, token.pos_) for token in spacy_doc]\n",
    "    \n",
    "    # Create a DataFrame for comparison\n",
    "    df = pd.DataFrame({\n",
    "        'Word': [word for word, _ in nltk_tags],\n",
    "        'NLTK Tag': [tag for _, tag in nltk_tags],\n",
    "        'spaCy Tag': [tag for word, tag in spacy_tags]\n",
    "    })\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nInput text: '{text}'\\n\")\n",
    "    print(\"POS Tagging Results:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Calculate tag distribution\n",
    "    print(\"\\nTag Distribution:\")\n",
    "    nltk_dist = pd.Series([tag for _, tag in nltk_tags]).value_counts()\n",
    "    spacy_dist = pd.Series([tag for _, tag in spacy_tags]).value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    nltk_dist.plot(kind='bar')\n",
    "    plt.title('NLTK Tag Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    spacy_dist.plot(kind='bar')\n",
    "    plt.title('spaCy Tag Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance comparison\n",
    "    import time\n",
    "    \n",
    "    def measure_performance(text, n_runs=100):\n",
    "        \"\"\"Measure performance of different taggers\"\"\"\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        # NLTK performance\n",
    "        nltk_start = time.time()\n",
    "        for _ in range(n_runs):\n",
    "            nltk.pos_tag(tokens)\n",
    "        nltk_time = (time.time() - nltk_start) / n_runs\n",
    "        \n",
    "        # spaCy performance\n",
    "        spacy_start = time.time()\n",
    "        for _ in range(n_runs):\n",
    "            nlp(text)\n",
    "        spacy_time = (time.time() - spacy_start) / n_runs\n",
    "        \n",
    "        return {\n",
    "            'NLTK': nltk_time,\n",
    "            'spaCy': spacy_time\n",
    "        }\n",
    "    \n",
    "    # Measure performance\n",
    "    perf_results = measure_performance(text)\n",
    "    \n",
    "    print(\"\\nPerformance Comparison (average time per run):\")\n",
    "    for tagger, time_taken in perf_results.items():\n",
    "        print(f\"{tagger}: {time_taken*1000:.2f} ms\")\n",
    "\n",
    "# Create interactive widget\n",
    "text_input = widgets.Textarea(\n",
    "    value='The quick brown fox jumps over the lazy dog.',\n",
    "    placeholder='Enter text for advanced POS tagging...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(compare_pos_taggers, text=text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe5409",
   "metadata": {},
   "source": [
    "### Understanding the Advanced Implementation\n",
    "\n",
    "This section demonstrates advanced POS tagging using popular NLP libraries. Here's what we're comparing:\n",
    "\n",
    "1. **NLTK Tagger**\n",
    "   - Uses the Perceptron Tagger\n",
    "   - Provides detailed Penn Treebank tags\n",
    "   - Good for general-purpose tagging\n",
    "\n",
    "2. **spaCy Tagger**\n",
    "   - Part of a complete NLP pipeline\n",
    "   - Uses a statistical model\n",
    "   - Provides universal POS tags\n",
    "\n",
    "3. **Performance Analysis**\n",
    "   - Compares processing speed\n",
    "   - Shows tag distribution\n",
    "   - Highlights differences in tagging approaches\n",
    "\n",
    "4. **Key Differences**\n",
    "   - Tag granularity (NLTK more detailed)\n",
    "   - Processing speed (spaCy generally faster)\n",
    "   - Integration with other NLP tasks\n",
    "\n",
    "Try entering different texts to see how the taggers perform and compare their results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b3ea0",
   "metadata": {},
   "source": [
    "<a id='visualization'></a>\n",
    "## 5. Data Flow Visualization\n",
    "\n",
    "Let's visualize how text flows through the POS tagging process, from tokenization to parsing. We'll create interactive visualizations to help understand the relationships between words and their grammatical roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb50b366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea64e0269b204f4bbfe31c01277d034b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The beautiful cat gracefully jumped over the fence.', description='Text:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.visualize_nlp_pipeline(text)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visualize_nlp_pipeline(text):\n",
    "    \"\"\"Visualize the NLP pipeline with POS tagging\"\"\"\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Token and POS Tag Visualization\n",
    "    plt.subplot(2, 2, 1)\n",
    "    tokens = [token.text for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    plt.bar(range(len(tokens)), [1] * len(tokens))\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=45, ha='right')\n",
    "    plt.yticks([])\n",
    "    plt.title('Tokens and POS Tags')\n",
    "    \n",
    "    # Add POS tags above the bars\n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        plt.text(i, 1.1, tag, ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Dependency Tree Visualization\n",
    "    plt.subplot(2, 2, 2)\n",
    "    dep_labels = [token.dep_ for token in doc]\n",
    "    dep_counts = pd.Series(dep_labels).value_counts()\n",
    "    dep_counts.plot(kind='bar')\n",
    "    plt.title('Dependency Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 3. POS Tag Distribution\n",
    "    plt.subplot(2, 2, 3)\n",
    "    pos_counts = pd.Series(pos_tags).value_counts()\n",
    "    pos_counts.plot(kind='bar')\n",
    "    plt.title('POS Tag Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 4. Word Relationships Network\n",
    "    plt.subplot(2, 2, 4)\n",
    "    import networkx as nx\n",
    "    \n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges based on dependencies\n",
    "    for token in doc:\n",
    "        if token.dep_ != 'ROOT':\n",
    "            G.add_edge(token.head.text, token.text, label=token.dep_)\n",
    "    \n",
    "    # Draw the graph\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', \n",
    "            node_size=2000, font_size=8, font_weight='bold')\n",
    "    \n",
    "    plt.title('Word Dependencies')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\nDetailed Analysis:\")\n",
    "    print(\"\\n1. Sentence Structure:\")\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            print(f\"Root word: {token.text} ({token.pos_})\")\n",
    "    \n",
    "    print(\"\\n2. Key Phrases:\")\n",
    "    for chunk in doc.noun_chunks:\n",
    "        print(f\"Noun phrase: {chunk.text}\")\n",
    "    \n",
    "    print(\"\\n3. Named Entities:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"{ent.text}: {ent.label_}\")\n",
    "    \n",
    "    print(\"\\n4. Dependencies:\")\n",
    "    for token in doc:\n",
    "        if token.dep_ != 'ROOT':\n",
    "            print(f\"{token.text} -> {token.head.text} ({token.dep_})\")\n",
    "\n",
    "# Create interactive widget\n",
    "text_input = widgets.Textarea(\n",
    "    value='The beautiful cat gracefully jumped over the fence.',\n",
    "    placeholder='Enter text to visualize...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(visualize_nlp_pipeline, text=text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bfc8db",
   "metadata": {},
   "source": [
    "### Understanding the Visualizations\n",
    "\n",
    "The interactive visualization above shows four different aspects of the POS tagging process:\n",
    "\n",
    "1. **Tokens and POS Tags**\n",
    "   - Shows each word in the sentence\n",
    "   - Displays its POS tag above\n",
    "   - Helps understand word categorization\n",
    "\n",
    "2. **Dependency Tree**\n",
    "   - Shows grammatical relationships between words\n",
    "   - Displays dependency labels\n",
    "   - Illustrates sentence structure\n",
    "\n",
    "3. **Tag Distribution**\n",
    "   - Shows frequency of different POS tags\n",
    "   - Helps understand tag patterns\n",
    "   - Useful for analysis\n",
    "\n",
    "4. **Word Relationship Network**\n",
    "   - Visualizes word connections\n",
    "   - Shows dependency structure\n",
    "   - Helps understand sentence complexity\n",
    "\n",
    "Try entering different sentences to see how the visualizations change and how different sentence structures are represented!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f920a",
   "metadata": {},
   "source": [
    "<a id='challenges'></a>\n",
    "## 6. Challenges & Edge Cases\n",
    "\n",
    "Let's explore common challenges in POS tagging and how different taggers handle edge cases. We'll look at ambiguous words, proper nouns, and domain-specific challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66e0e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ed2d726a28482a976495d697770c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The CEO of Apple Inc. announced a new iPhone model.', description='Text:…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_challenges(text)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def explore_challenges(text):\n",
    "    \"\"\"Explore POS tagging challenges and edge cases\"\"\"\n",
    "    # Process text with different taggers\n",
    "    doc = nlp(text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    nltk_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Create a DataFrame for comparison\n",
    "    df = pd.DataFrame({\n",
    "        'Word': [token.text for token in doc],\n",
    "        'NLTK Tag': [tag for word, tag in nltk_tags],\n",
    "        'spaCy Tag': [token.pos_ for token in doc],\n",
    "        'Dependency': [token.dep_ for token in doc]\n",
    "    })\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nInput text: '{text}'\\n\")\n",
    "    print(\"POS Tagging Results:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Identify potential challenges\n",
    "    print(\"\\nPotential Challenges:\")\n",
    "    \n",
    "    # 1. Ambiguous words\n",
    "    ambiguous_words = []\n",
    "    for i, row in df.iterrows():\n",
    "        if row['NLTK Tag'] != row['spaCy Tag']:\n",
    "            ambiguous_words.append(row['Word'])\n",
    "    \n",
    "    if ambiguous_words:\n",
    "        print(\"\\n1. Ambiguous Words:\")\n",
    "        for word in ambiguous_words:\n",
    "            print(f\"- {word}: NLTK and spaCy disagree on its POS tag\")\n",
    "    \n",
    "    # 2. Proper nouns\n",
    "    proper_nouns = [word for word, tag in nltk_tags if tag.startswith('NNP')]\n",
    "    if proper_nouns:\n",
    "        print(\"\\n2. Proper Nouns:\")\n",
    "        for word in proper_nouns:\n",
    "            print(f\"- {word}: Identified as a proper noun\")\n",
    "    \n",
    "    # 3. Compound words\n",
    "    compound_words = []\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.dep_ == 'compound':\n",
    "            compound_words.append((token.text, token.head.text))\n",
    "    \n",
    "    if compound_words:\n",
    "        print(\"\\n3. Compound Words:\")\n",
    "        for word, head in compound_words:\n",
    "            print(f\"- {word} + {head}: Compound noun\")\n",
    "    \n",
    "    # 4. Domain-specific terms\n",
    "    domain_terms = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN' and token.text.isupper():\n",
    "            domain_terms.append(token.text)\n",
    "    \n",
    "    if domain_terms:\n",
    "        print(\"\\n4. Domain-Specific Terms:\")\n",
    "        for term in domain_terms:\n",
    "            print(f\"- {term}: Possible domain-specific term\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 1. Tag agreement visualization\n",
    "    plt.subplot(1, 2, 1)\n",
    "    agreement = [1 if row['NLTK Tag'] == row['spaCy Tag'] else 0 for _, row in df.iterrows()]\n",
    "    plt.bar(range(len(agreement)), agreement)\n",
    "    plt.title('Tag Agreement')\n",
    "    plt.xticks(range(len(df['Word'])), df['Word'], rotation=45, ha='right')\n",
    "    plt.yticks([0, 1], ['Disagree', 'Agree'])\n",
    "    \n",
    "    # 2. Dependency visualization\n",
    "    plt.subplot(1, 2, 2)\n",
    "    dep_counts = df['Dependency'].value_counts()\n",
    "    dep_counts.plot(kind='bar')\n",
    "    plt.title('Dependency Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widget\n",
    "text_input = widgets.Textarea(\n",
    "    value='The CEO of Apple Inc. announced a new iPhone model.',\n",
    "    placeholder='Enter text to explore challenges...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(explore_challenges, text=text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6c979",
   "metadata": {},
   "source": [
    "### Understanding the Challenges\n",
    "\n",
    "This section explores common challenges in POS tagging:\n",
    "\n",
    "1. **Ambiguous Words**\n",
    "   - Words that can have multiple POS tags\n",
    "   - Context-dependent meanings\n",
    "   - Different interpretations by different taggers\n",
    "\n",
    "2. **Proper Nouns**\n",
    "   - Names of people, organizations, places\n",
    "   - Often capitalized\n",
    "   - Can be compound or multi-word\n",
    "\n",
    "3. **Compound Words**\n",
    "   - Multi-word expressions\n",
    "   - Special grammatical structures\n",
    "   - Domain-specific terminology\n",
    "\n",
    "4. **Domain-Specific Terms**\n",
    "   - Technical vocabulary\n",
    "   - Industry-specific terms\n",
    "   - Abbreviations and acronyms\n",
    "\n",
    "Try entering different types of text to see how the taggers handle these challenges!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb14e61-2efa-42dc-aa54-87effc8d7ef4",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## 7. Conclusion & Further Reading\n",
    "\n",
    "In this workshop, we've explored the fundamentals and advanced concepts of Parts of Speech (POS) tagging. Let's summarize what we've learned and look at where to go next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10c913d7-9f9d-4a3b-8a83-d2e9a299d5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0702b08595c64ff9b815eb899878eab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The quick brown fox jumps over the lazy dog.', description='Text:', layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.summarize_workshop(text)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_workshop(text):\n",
    "    \"\"\"Summarize the key concepts learned in the workshop\"\"\"\n",
    "    # Process text with different taggers\n",
    "    doc = nlp(text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    nltk_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Word': [token.text for token in doc],\n",
    "        'POS Tag': [tag for word, tag in nltk_tags],\n",
    "        'Dependency': [token.dep_ for token in doc],\n",
    "        'Lemma': [token.lemma_ for token in doc]\n",
    "    })\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nFinal Analysis of: '{text}'\\n\")\n",
    "    print(\"Complete POS Analysis:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 1. POS Tag Distribution\n",
    "    plt.subplot(1, 3, 1)\n",
    "    pos_counts = df['POS Tag'].value_counts()\n",
    "    pos_counts.plot(kind='bar')\n",
    "    plt.title('POS Tag Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. Dependency Distribution\n",
    "    plt.subplot(1, 3, 2)\n",
    "    dep_counts = df['Dependency'].value_counts()\n",
    "    dep_counts.plot(kind='bar')\n",
    "    plt.title('Dependency Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 3. Word vs Lemma Length\n",
    "    plt.subplot(1, 3, 3)\n",
    "    df['Word Length'] = df['Word'].str.len()\n",
    "    df['Lemma Length'] = df['Lemma'].str.len()\n",
    "    plt.scatter(df['Word Length'], df['Lemma Length'])\n",
    "    plt.title('Word vs Lemma Length')\n",
    "    plt.xlabel('Word Length')\n",
    "    plt.ylabel('Lemma Length')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"Total words: {len(tokens)}\")\n",
    "    print(f\"Unique POS tags: {len(pos_counts)}\")\n",
    "    print(f\"Unique dependencies: {len(dep_counts)}\")\n",
    "    \n",
    "    # Print key insights using iloc to avoid FutureWarning\n",
    "    print(\"\\nKey Insights:\")\n",
    "    print(\"1. Most common POS tags:\", pos_counts.index[0], \"(\", pos_counts.iloc[0], \"occurrences)\")\n",
    "    print(\"2. Most common dependency:\", dep_counts.index[0], \"(\", dep_counts.iloc[0], \"occurrences)\")\n",
    "    print(\"3. Average word length:\", df['Word Length'].mean())\n",
    "    print(\"4. Average lemma length:\", df['Lemma Length'].mean())\n",
    "\n",
    "# Create interactive widget\n",
    "text_input = widgets.Textarea(\n",
    "    value='The quick brown fox jumps over the lazy dog.',\n",
    "    placeholder='Enter text for final analysis...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(summarize_workshop, text=text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ecacbb-d15f-4f6e-9fc3-ef5a0906a28c",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "1. **Fundamental Concepts**\n",
    "   - Understanding POS tagging basics\n",
    "   - Different tagging approaches\n",
    "   - Rule-based vs. statistical methods\n",
    "\n",
    "2. **Advanced Techniques**\n",
    "   - Deep learning-based tagging\n",
    "   - Context-aware tagging\n",
    "   - Handling edge cases\n",
    "\n",
    "3. **Practical Applications**\n",
    "   - Text preprocessing\n",
    "   - Information extraction\n",
    "   - Natural language understanding\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "1. **Academic Papers**\n",
    "   - \"Deep Learning for POS Tagging\" by Collobert et al.\n",
    "   - \"BERT: Pre-training of Deep Bidirectional Transformers\" by Devlin et al.\n",
    "   - \"Universal Dependencies\" by Nivre et al.\n",
    "\n",
    "2. **Online Resources**\n",
    "   - [NLTK Documentation](https://www.nltk.org/)\n",
    "   - [spaCy Documentation](https://spacy.io/)\n",
    "   - [Stanford NLP Group](https://nlp.stanford.edu/)\n",
    "\n",
    "3. **Related Topics**\n",
    "   - Named Entity Recognition (NER)\n",
    "   - Dependency Parsing\n",
    "   - Constituency Parsing\n",
    "   - Semantic Role Labeling\n",
    "\n",
    "### Practice Exercises\n",
    "\n",
    "1. **Basic Exercises**\n",
    "   - Implement a custom POS tagger\n",
    "   - Compare different tagging methods\n",
    "   - Analyze tag distributions\n",
    "\n",
    "2. **Advanced Challenges**\n",
    "   - Handle domain-specific text\n",
    "   - Implement context-aware tagging\n",
    "   - Build a custom tagger for specific languages\n",
    "\n",
    "3. **Real-World Projects**\n",
    "   - Build a grammar checker\n",
    "   - Create a text summarizer\n",
    "   - Develop a question-answering system\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Advanced Topics**\n",
    "   - Deep learning for POS tagging\n",
    "   - Multilingual POS tagging\n",
    "   - Domain-specific tagging\n",
    "\n",
    "2. **Practical Applications**\n",
    "   - Text classification\n",
    "   - Sentiment analysis\n",
    "   - Machine translation\n",
    "\n",
    "3. **Research Areas**\n",
    "   - Novel tagging architectures\n",
    "   - Cross-lingual transfer learning\n",
    "   - Zero-shot POS tagging\n",
    "\n",
    "Remember to experiment with different texts and analyze how POS tagging behaves in various contexts. The more you practice, the better you'll understand the nuances of natural language processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47201d-23cf-44b7-8068-24b0f3a18ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
